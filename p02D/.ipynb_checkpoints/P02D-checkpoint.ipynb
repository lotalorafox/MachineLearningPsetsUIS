{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra exercise \n",
    "Create a model to clasify face images with a random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import sys\n",
    "sys.path.append(\"code\")\n",
    "from haar import *\n",
    "import os\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "\n",
    "#import the images\n",
    "base_dir = \"faces/\"\n",
    "dir_positives = base_dir+\"positives\"\n",
    "dir_negatives = base_dir+\"negatives\"\n",
    "positive_filenames = os.listdir(dir_positives)\n",
    "negative_filenames = os.listdir(dir_negatives)\n",
    "\n",
    "pos_imgs = []\n",
    "neg_imgs = []\n",
    "\n",
    "for i in positive_filenames:\n",
    "    img = io.imread(dir_positives+\"/\"+i).astype(int)\n",
    "    pos_imgs.append(img)\n",
    "\n",
    "for i in negative_filenames:\n",
    "    img = io.imread(dir_negatives+\"/\"+i).astype(int)\n",
    "    neg_imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"loaded\", len(pos_imgs), \"positive images and\", len(neg_imgs), \"negative images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the harr features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the haar features\n",
    "haar_1 = [ {\"op\": \"add\", \"topleft_row_rel\": 0.0, \"topleft_col_rel\": 0.0, \"height_rel\": 0.5, \"width_rel\": 1.0},\n",
    "           {\"op\": \"sub\", \"topleft_row_rel\": 0.5, \"topleft_col_rel\": 0.0, \"height_rel\": 0.5, \"width_rel\": 1.0}]\n",
    "\n",
    "haar_2 = [ {\"op\": \"add\", \"topleft_row_rel\": 0.0, \"topleft_col_rel\": 0.0, \"height_rel\": 1.0, \"width_rel\": 0.5},\n",
    "           {\"op\": \"sub\", \"topleft_row_rel\": 0.0, \"topleft_col_rel\": 0.5, \"height_rel\": 1.0, \"width_rel\": 0.5}]\n",
    "\n",
    "haar_3 = [ {\"op\": \"add\", \"topleft_row_rel\": 0.0,   \"topleft_col_rel\": 0.0, \"height_rel\": 0.3, \"width_rel\": 1.0},\n",
    "           {\"op\": \"add\", \"topleft_row_rel\": 0.7,   \"topleft_col_rel\": 0.0, \"height_rel\": 0.3, \"width_rel\": 1.0},\n",
    "           {\"op\": \"sub\", \"topleft_row_rel\": 0.3,   \"topleft_col_rel\": 0.0, \"height_rel\": 0.4, \"width_rel\": 1.0}]\n",
    "\n",
    "haar_4 = [ {\"op\": \"add\", \"topleft_row_rel\": 0.0, \"topleft_col_rel\": 0.0, \"height_rel\": 1.0, \"width_rel\": 0.3},\n",
    "           {\"op\": \"add\", \"topleft_row_rel\": 0.0, \"topleft_col_rel\": 0.7, \"height_rel\": 1.0, \"width_rel\": 0.3},\n",
    "           {\"op\": \"sub\", \"topleft_row_rel\": 0.0, \"topleft_col_rel\": 0.3, \"height_rel\": 1.0, \"width_rel\": 0.4}]\n",
    "\n",
    "show_haar_features([haar_1, haar_2, haar_3, haar_4])\n",
    "haar_features = [ haar_1, haar_2, haar_3, haar_4 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "put the haar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_haar_dataset_for_faces(haar_features, positive_images, negative_images, N):\n",
    "    datos     = []\n",
    "    etiquetas = []\n",
    "    # positive\n",
    "    i =0\n",
    "    while i<len(positive_images):\n",
    "        datos.append(get_haar_features(haar_features, positive_images[i], get_integral(positive_images[i]), nb_scales=N, nb_shifts=N))\n",
    "        etiquetas.append(1)\n",
    "        i+=1\n",
    "    j = i\n",
    "    r = j+len(negative_images)\n",
    "    while j<len(negative_images):\n",
    "        datos.append(get_haar_features(haar_features, negative_images[j], get_integral(negative_images[j]), nb_scales=N, nb_shifts=N))\n",
    "        etiquetas.append(0)\n",
    "        j+=1\n",
    "    datos = np.array(datos)\n",
    "    etiquetas = np.array(etiquetas)\n",
    "    return datos, etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d,c = make_haar_dataset_for_faces(haar_features, pos_imgs, neg_imgs, 6)\n",
    "print (d.shape, c.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "est = RandomForestClassifier(n_estimators=50)\n",
    "sc = cross_val_score(est, d, c, cv=10)\n",
    "print(np.mean(sc), np.std(sc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
